{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyo0914/hw3/blob/main/hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj693cdHrO3y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HCjW9n6ampXr"
      },
      "outputs": [],
      "source": [
        "!pip install torch-fidelity\n",
        "!pip install torchmetrics[image] -U\n",
        "!pip install torchmetrics\n",
        "!pip install -q diffusers transformers accelerate huggingface_hub\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIVl9hqHrh3m"
      },
      "source": [
        "#prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ria2l-RKu3w2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "def load_model():\n",
        "    model_name = \"Salesforce/blip2-opt-2.7b\"\n",
        "    processor = AutoProcessor.from_pretrained(model_name)\n",
        "    model = Blip2ForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    return processor, model\n",
        "\n",
        "def clean_description(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,]', '', text)\n",
        "    text = re.sub(r'Describe the scene.*?detail\\.?\\s*', '', text)\n",
        "    text = re.sub(r'What is.*?\\?', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def load_and_preprocess_images(image_paths: List[str], processor) -> Tuple[torch.Tensor, List[str]]:\n",
        "    images = []\n",
        "    valid_paths = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            images.append(image)\n",
        "            valid_paths.append(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    if not images:\n",
        "        return None, []\n",
        "\n",
        "    inputs = processor(\n",
        "        images=images,\n",
        "        text=[\"A photograph of\"] * len(images),\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device=\"cuda\", dtype=torch.float16)\n",
        "\n",
        "    return inputs, valid_paths\n",
        "\n",
        "def generate_batch_descriptions(image_paths: List[str], processor, model, batch_size=2):\n",
        "    try:\n",
        "        inputs, valid_paths = load_and_preprocess_images(image_paths, processor)\n",
        "        if inputs is None:\n",
        "            return {}\n",
        "\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=True,\n",
        "            num_beams=3,\n",
        "            max_length=50,\n",
        "            min_length=10,\n",
        "            length_penalty=1.0,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "\n",
        "        descriptions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "        descriptions = [clean_description(desc) for desc in descriptions]\n",
        "\n",
        "        return dict(zip(valid_paths, descriptions))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in batch generation: {e}\")\n",
        "        return {}\n",
        "\n",
        "def add_safety_prompts(description):\n",
        "    if not description.strip():\n",
        "        return None\n",
        "\n",
        "    positive = \"professional photograph, photorealistic, 8k uhd, sharp focus, site visibility, safety focus, natural site lighting, warm industrial tones\"\n",
        "    negative = \"deformed, blurry, bad anatomy, distorted, poor quality, low quality, mutation, artificial, unnatural, cartoon, anime, illustration, painting, drawing, rendering, 3d, cg, digital art, toy tools, fake safety gear\"\n",
        "\n",
        "    return f\"{description}, {positive} ### {negative}\"\n",
        "\n",
        "def generate_prompts(json_data, image_folder, processor, model, batch_size=2):\n",
        "    results = []\n",
        "    image_folder = Path(image_folder)\n",
        "    total_images = len(json_data)\n",
        "\n",
        "    try:\n",
        "        with open('intermediate_results.json', 'r', encoding='utf-8') as f:\n",
        "            results = json.load(f)\n",
        "            print(f\"Loaded {len(results)} existing results\")\n",
        "            processed_images = set(item['image'] for item in results)\n",
        "    except FileNotFoundError:\n",
        "        results = []\n",
        "        processed_images = set()\n",
        "\n",
        "    pending_items = [item for item in json_data if item['image'] not in processed_images]\n",
        "\n",
        "    for i in tqdm(range(0, len(pending_items), batch_size), desc=\"Processing batches\"):\n",
        "        batch_items = pending_items[i:i + batch_size]\n",
        "        batch_paths = [str(image_folder / item[\"image\"]) for item in batch_items]\n",
        "\n",
        "        print(f\"\\nProcessing batch {i//batch_size + 1}, images {i+1}-{min(i+batch_size, len(pending_items))}\")\n",
        "\n",
        "        descriptions = generate_batch_descriptions(batch_paths, processor, model, batch_size)\n",
        "\n",
        "        for item, img_path in zip(batch_items, batch_paths):\n",
        "            if img_path not in descriptions:\n",
        "                print(f\"Skipping {item['image']} due to generation error\")\n",
        "                continue\n",
        "\n",
        "            generated_text = descriptions[img_path]\n",
        "            original_labels = \", \".join(item[\"labels\"])\n",
        "\n",
        "            new_item = item.copy()\n",
        "            new_item['generated_text'] = generated_text\n",
        "            new_item['prompt_w_label'] = f\"{generated_text}, {original_labels}\"\n",
        "            new_item['prompt_w_suffix'] = add_safety_prompts(f\"{generated_text}, {original_labels}\")\n",
        "\n",
        "            results.append(new_item)\n",
        "\n",
        "            print(f\"\\nGenerated for {item['image']}:\")\n",
        "            print(f\"Text: {generated_text}\")\n",
        "\n",
        "        with open('intermediate_results.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Saved progress: {len(results)}/{total_images} images processed\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    print(\"Starting prompt generation for all images...\")\n",
        "\n",
        "    image_folder = \"/content/drive/MyDrive/hw/images\"\n",
        "    json_path = \"/content/drive/MyDrive/hw/label.json\"\n",
        "\n",
        "    BATCH_SIZE = 2\n",
        "\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    print(f\"JSON data loaded successfully with {len(json_data)} items\")\n",
        "\n",
        "    print(\"Loading BLIP-2 model...\")\n",
        "    processor, model = load_model()\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    results = generate_prompts(json_data, image_folder, processor, model, BATCH_SIZE)\n",
        "\n",
        "    output_path = \"/content/drive/MyDrive/hw/final_generated_prompts.json\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nFinal results saved to {output_path}\")\n",
        "    print(f\"Processed {len(results)} images in total\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NFzir2zrcXO"
      },
      "source": [
        "#generate picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4SUHulDq3Mza"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from torch.cuda import empty_cache\n",
        "from contextlib import nullcontext\n",
        "\n",
        "def ensure_directories(base_dir):\n",
        "    directories = [\n",
        "        f\"{base_dir}/generated_text\",\n",
        "        f\"{base_dir}/prompt_w_label\",\n",
        "        f\"{base_dir}/prompt_w_suffix\"\n",
        "    ]\n",
        "    for dir_path in directories:\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        print(f\"Ensured directory exists: {dir_path}\")\n",
        "\n",
        "def check_drive_mounted():\n",
        "    if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Google Drive not mounted. Mounting now...\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Google Drive mounted successfully\")\n",
        "\n",
        "def load_model():\n",
        "    model_id = \"SG161222/Realistic_Vision_V2.0\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    pipe.enable_attention_slicing()\n",
        "    return pipe\n",
        "\n",
        "def process_prompt_suffix(prompt_text):\n",
        "    if \"###\" in prompt_text:\n",
        "        positive, negative = prompt_text.split(\"###\")\n",
        "        return positive.strip(), negative.strip()\n",
        "    return prompt_text.strip(), \"\"\n",
        "\n",
        "def get_completed_images(output_dirs):\n",
        "    completed = set()\n",
        "    for dir_path in output_dirs.values():\n",
        "        if dir_path.exists():\n",
        "            for file_path in dir_path.glob(\"*.png\"):\n",
        "                base_name = file_path.stem.split('_')[0]\n",
        "                completed.add(base_name)\n",
        "    return completed\n",
        "\n",
        "def save_progress(current_index, progress_file):\n",
        "    with open(progress_file, 'w') as f:\n",
        "        json.dump({'last_processed_index': current_index}, f)\n",
        "\n",
        "def load_progress(progress_file):\n",
        "    try:\n",
        "        with open(progress_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            return data.get('last_processed_index', -1)\n",
        "    except FileNotFoundError:\n",
        "        return -1\n",
        "\n",
        "def generate_images_batch(pipe, batch_items, output_dirs, gen_kwargs):\n",
        "    for prompt_type in ['generated_text', 'prompt_w_label', 'prompt_w_suffix']:\n",
        "        batch_prompts = []\n",
        "        batch_negative_prompts = []\n",
        "        batch_paths = []\n",
        "        batch_indices = []\n",
        "\n",
        "        for idx, item in enumerate(batch_items):\n",
        "            prompt = item.get(prompt_type, \"\")\n",
        "            if not prompt:\n",
        "                continue\n",
        "\n",
        "            base_filename = Path(item['image']).stem\n",
        "            output_filename = f\"{base_filename}_{prompt_type}.png\"\n",
        "            output_path = output_dirs[prompt_type] / output_filename\n",
        "\n",
        "            if output_path.exists():\n",
        "                print(f\"Skipping existing image: {output_path}\")\n",
        "                continue\n",
        "\n",
        "            if prompt_type == 'prompt_w_suffix':\n",
        "                positive_prompt, negative_prompt = process_prompt_suffix(prompt)\n",
        "                batch_prompts.append(positive_prompt)\n",
        "                batch_negative_prompts.append(negative_prompt)\n",
        "            else:\n",
        "                batch_prompts.append(prompt)\n",
        "                batch_negative_prompts.append(\"\")\n",
        "\n",
        "            batch_paths.append(output_path)\n",
        "            batch_indices.append(idx)\n",
        "\n",
        "        if not batch_prompts:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                if prompt_type == 'prompt_w_suffix':\n",
        "                    images = pipe(\n",
        "                        prompt=batch_prompts,\n",
        "                        negative_prompt=batch_negative_prompts,\n",
        "                        num_images_per_prompt=1,\n",
        "                        **gen_kwargs\n",
        "                    ).images\n",
        "                else:\n",
        "                    images = pipe(\n",
        "                        prompt=batch_prompts,\n",
        "                        num_images_per_prompt=1,\n",
        "                        **gen_kwargs\n",
        "                    ).images\n",
        "\n",
        "                for img, path in zip(images, batch_paths):\n",
        "                    img.save(str(path))\n",
        "                    print(f\"Saved image to {path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating {prompt_type} images: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        empty_cache()\n",
        "\n",
        "def generate_images(pipe, prompt_data, base_output_dir, batch_size=32):\n",
        "    output_dirs = {\n",
        "        'generated_text': Path(base_output_dir) / 'generated_text',\n",
        "        'prompt_w_label': Path(base_output_dir) / 'prompt_w_label',\n",
        "        'prompt_w_suffix': Path(base_output_dir) / 'prompt_w_suffix'\n",
        "    }\n",
        "\n",
        "    for dir_path in output_dirs.values():\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        print(f\"Ensured directory exists: {dir_path}\")\n",
        "\n",
        "    progress_file = Path(base_output_dir) / 'generation_progress.json'\n",
        "    last_processed = load_progress(progress_file)\n",
        "\n",
        "    completed_images = get_completed_images(output_dirs)\n",
        "    print(f\"Found {len(completed_images)} completed images\")\n",
        "\n",
        "    gen_kwargs = {\n",
        "        \"num_inference_steps\": 40,\n",
        "        \"guidance_scale\": 7.5,\n",
        "        \"height\": 512,\n",
        "        \"width\": 512,\n",
        "    }\n",
        "\n",
        "    start_idx = max(0, last_processed + 1)\n",
        "    end_idx = len(prompt_data)\n",
        "\n",
        "    for i in tqdm(range(start_idx, end_idx, batch_size),\n",
        "                 desc=\"Processing batches\",\n",
        "                 initial=start_idx//batch_size,\n",
        "                 total=(end_idx-start_idx+batch_size-1)//batch_size):\n",
        "        batch_items = prompt_data[i:min(i + batch_size, end_idx)]\n",
        "\n",
        "        batch_needed = False\n",
        "        for item in batch_items:\n",
        "            base_name = Path(item['image']).stem\n",
        "            if base_name not in completed_images:\n",
        "                batch_needed = True\n",
        "                break\n",
        "\n",
        "        if not batch_needed:\n",
        "            print(f\"Skipping completed batch {i//batch_size + 1}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing batch {i//batch_size + 1}\")\n",
        "        generate_images_batch(pipe, batch_items, output_dirs, gen_kwargs)\n",
        "\n",
        "        save_progress(i + len(batch_items) - 1, progress_file)\n",
        "        empty_cache()\n",
        "\n",
        "def main():\n",
        "    print(\"Starting image generation...\")\n",
        "\n",
        "    check_drive_mounted()\n",
        "\n",
        "    input_json = \"/content/drive/MyDrive/hw/final_generated_prompts.json\"\n",
        "    output_dir = \"/content/drive/MyDrive/hw/generated_images\"\n",
        "\n",
        "    ensure_directories(output_dir)\n",
        "\n",
        "    if not os.path.exists(input_json):\n",
        "        raise FileNotFoundError(f\"Cannot find input file: {input_json}\")\n",
        "\n",
        "    with open(input_json, 'r', encoding='utf-8') as f:\n",
        "        prompt_data = json.load(f)\n",
        "\n",
        "    print(f\"Loaded {len(prompt_data)} prompts from {input_json}\")\n",
        "\n",
        "    print(\"Loading Realistic Vision V2.0 model...\")\n",
        "    pipe = load_model()\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    generate_images(pipe, prompt_data, output_dir, batch_size=BATCH_SIZE)\n",
        "\n",
        "    print(\"\\nImage generation completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTavaq8NrfUI"
      },
      "source": [
        "#calculate FID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IB_2gIrNeinA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_fid(generated_dirs, orig_dir):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    results = {}\n",
        "\n",
        "    for prompt_type, gen_dir in generated_dirs.items():\n",
        "        print(f\"\\nCalculating FID for {prompt_type}...\")\n",
        "        fid = FrechetInceptionDistance(normalize=True).to(device)\n",
        "        score = _calculate_single_fid(orig_dir, gen_dir, fid)\n",
        "        results[prompt_type] = score\n",
        "        fid.reset()\n",
        "\n",
        "    return results\n",
        "\n",
        "def _calculate_single_fid(orig_dir, gen_dir, fid):\n",
        "    generated_images = [f for f in os.listdir(gen_dir) if f.endswith('.png')]\n",
        "\n",
        "    for gen_img_name in tqdm(generated_images, desc=\"Processing images\"):\n",
        "        orig_img_name = gen_img_name.split('_')[0] + '.jpeg'\n",
        "\n",
        "        try:\n",
        "            orig_path = os.path.join(orig_dir, orig_img_name)\n",
        "            if os.path.exists(orig_path):\n",
        "                orig_img = process_image(orig_path)\n",
        "                fid.update(orig_img, real=True)\n",
        "\n",
        "                gen_path = os.path.join(gen_dir, gen_img_name)\n",
        "                gen_img = process_image(gen_path)\n",
        "                fid.update(gen_img, real=False)\n",
        "            else:\n",
        "                print(f\"Original image not found: {orig_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {gen_img_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return float(fid.compute())\n",
        "\n",
        "def process_image(image_path):\n",
        "\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    img = img.resize((512, 512), Image.Resampling.LANCZOS)\n",
        "\n",
        "    img = img.resize((299, 299), Image.Resampling.LANCZOS)\n",
        "\n",
        "    img = torch.from_numpy(np.array(img)).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "    return img.cuda()\n",
        "\n",
        "def main():\n",
        "    orig_dir = \"/content/drive/MyDrive/hw/images\"\n",
        "    generated_dirs = {\n",
        "        'generated_text': \"/content/drive/MyDrive/hw/generated_images/generated_text\",\n",
        "        'prompt_w_label': \"/content/drive/MyDrive/hw/generated_images/prompt_w_label\",\n",
        "        'prompt_w_suffix': \"/content/drive/MyDrive/hw/generated_images/prompt_w_suffix\"\n",
        "    }\n",
        "\n",
        "    for dir_path in [orig_dir] + list(generated_dirs.values()):\n",
        "        if not os.path.exists(dir_path):\n",
        "            raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
        "\n",
        "    print(\"Starting FID calculation...\")\n",
        "\n",
        "    results = calculate_fid(generated_dirs, orig_dir)\n",
        "\n",
        "    print(\"\\nFID Scores:\")\n",
        "    for prompt_type, score in results.items():\n",
        "        print(f\"{prompt_type}: {score:.2f}\")\n",
        "\n",
        "    output_path = \"/content/drive/MyDrive/hw/fid_results.json\"\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\nResults saved to {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYIqVBwrnFl"
      },
      "source": [
        "#picture with layout&image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r4P1whSQrlPd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import HfApi, hf_hub_download\n",
        "import time\n",
        "\n",
        "def download_model_with_retry(model_id, max_retries=3):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Downloading model attempt {attempt + 1}/{max_retries}\")\n",
        "            pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                model_id,\n",
        "                torch_dtype=torch.float16,\n",
        "                low_cpu_mem_usage=True,\n",
        "                resume_download=True,\n",
        "                local_files_only=False\n",
        "            )\n",
        "            return pipe\n",
        "        except Exception as e:\n",
        "            print(f\"Download attempt {attempt + 1} failed: {str(e)}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 2 ** attempt\n",
        "                print(f\"Waiting {wait_time} seconds before retrying...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                raise Exception(f\"Failed to download model after {max_retries} attempts\")\n",
        "\n",
        "def load_checkpoint():\n",
        "    checkpoint_path = \"/content/drive/MyDrive/hw/checkpoint.json\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        with open(checkpoint_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return {\"completed_images\": []}\n",
        "\n",
        "def save_checkpoint(completed_images):\n",
        "    checkpoint_path = \"/content/drive/MyDrive/hw/checkpoint.json\"\n",
        "    with open(checkpoint_path, 'w') as f:\n",
        "        json.dump({\"completed_images\": completed_images}, f)\n",
        "\n",
        "def create_layout_mask(bboxes, height, width):\n",
        "    mask = np.zeros((height, width))\n",
        "    for bbox in bboxes:\n",
        "        x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
        "        mask[y1:y2, x1:x2] = 1\n",
        "    return mask\n",
        "\n",
        "def process_batch(pipe, batch_items, output_dir, completed_images):\n",
        "    batch_prompts = []\n",
        "    batch_reference_images = []\n",
        "    batch_masks = []\n",
        "\n",
        "    for item in batch_items:\n",
        "        ref_image_path = os.path.join(\"/content/drive/MyDrive/hw/images\", item[\"image\"])\n",
        "        if os.path.exists(ref_image_path):\n",
        "            reference_image = Image.open(ref_image_path).convert(\"RGB\")\n",
        "\n",
        "            layout_mask = create_layout_mask(\n",
        "                item[\"bboxes\"],\n",
        "                item[\"height\"],\n",
        "                item[\"width\"]\n",
        "            )\n",
        "            layout_mask = Image.fromarray((layout_mask * 255).astype(np.uint8))\n",
        "\n",
        "            batch_prompts.append(item[\"generated_text\"])  # Using generated_text instead of prompt_w_suffix\n",
        "            batch_reference_images.append(reference_image)\n",
        "            batch_masks.append(layout_mask)\n",
        "\n",
        "    try:\n",
        "        # Generate images in batch\n",
        "        generated_images = pipe(\n",
        "            prompt=batch_prompts,\n",
        "            image=batch_reference_images,\n",
        "            mask_image=batch_masks,\n",
        "            num_inference_steps=50,\n",
        "            guidance_scale=7.5\n",
        "        ).images\n",
        "\n",
        "        # Save generated images\n",
        "        for i, generated_image in enumerate(generated_images):\n",
        "            output_path = os.path.join(output_dir, f\"generated_{batch_items[i]['image']}\")\n",
        "            generated_image.save(output_path)\n",
        "            completed_images.append(batch_items[i]['image'])\n",
        "\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"CUDA out of memory.\")\n",
        "        for item in batch_items:\n",
        "            try:\n",
        "                process_batch([item], output_dir, completed_images)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing single item {item['image']}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "def validate_checkpoint(completed_images, output_dir):\n",
        "    validated_images = []\n",
        "    for image_name in completed_images:\n",
        "        output_path = os.path.join(output_dir, f\"generated_{image_name}\")\n",
        "        if os.path.exists(output_path):\n",
        "            validated_images.append(image_name)\n",
        "    return validated_images\n",
        "\n",
        "def main():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"model download...\")\n",
        "    model_id = \"SG161222/Realistic_Vision_V2.0\"\n",
        "\n",
        "    try:\n",
        "        pipe = download_model_with_retry(model_id)\n",
        "        pipe = pipe.to(\"cuda\")\n",
        "        print(\"Model downloaded and loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    print(\"Loading JSON data...\")\n",
        "    with open(\"/content/drive/MyDrive/hw/final_generated_prompts.json\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    output_dir = \"/content/drive/MyDrive/hw/generated_images/layout\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    checkpoint = load_checkpoint()\n",
        "    completed_images = validate_checkpoint(checkpoint[\"completed_images\"], output_dir)\n",
        "    print(f\"Found {len(completed_images)} valid completed images\")\n",
        "\n",
        "    batch_size = 4\n",
        "    try:\n",
        "        current_batch = []\n",
        "        for item in tqdm(data, desc=\"Processing images\"):\n",
        "            if item[\"image\"] in completed_images:\n",
        "                if os.path.exists(os.path.join(output_dir, f\"generated_{item['image']}\")):\n",
        "                    print(f\"Skipping {item['image']} - already processed\")\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"Regenerating {item['image']} - output file not found\")\n",
        "\n",
        "            current_batch.append(item)\n",
        "\n",
        "            if len(current_batch) == batch_size:\n",
        "                process_batch(pipe, current_batch, output_dir, completed_images)\n",
        "                save_checkpoint(completed_images)\n",
        "                current_batch = []\n",
        "        if current_batch:\n",
        "            process_batch(pipe, current_batch, output_dir, completed_images)\n",
        "            save_checkpoint(completed_images)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted. Progress saved in checkpoint.\")\n",
        "        save_checkpoint(completed_images)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "        save_checkpoint(completed_images)\n",
        "        raise e\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}